{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba7cddf",
   "metadata": {},
   "source": [
    "1. Define Artificial Intelligence (AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6ea95",
   "metadata": {},
   "source": [
    "Artificial Intelligence (AI) is the simulation of human intelligence in machines that are programmed to think, learn, and make decisions like humans. It includes capabilities such as reasoning, problem-solving, understanding language, and perception."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b96c50",
   "metadata": {},
   "source": [
    "2. Explain the differences between Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), \n",
    "and Data Science (DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a833e",
   "metadata": {},
   "source": [
    "| Concept                          | Description                                                                                                                                        |\n",
    "| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Artificial Intelligence (AI)** | A broad field focused on creating machines capable of intelligent behavior.                                                                        |\n",
    "| **Machine Learning (ML)**        | A subset of AI that enables systems to learn from data and improve over time without being explicitly programmed.                                  |\n",
    "| **Deep Learning (DL)**           | A subset of ML that uses neural networks with many layers (deep networks) to analyze complex patterns in large datasets.                           |\n",
    "| **Data Science (DS)**            | A multidisciplinary field that uses statistical, mathematical, and computational methods to extract insights from data. It may use AI/ML as tools. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9408c",
   "metadata": {},
   "source": [
    "3. How does AI differ from traditional software development?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7056fde",
   "metadata": {},
   "source": [
    "| Aspect                  | Traditional Software               | AI-based Systems                           |\n",
    "| ----------------------- | ---------------------------------- | ------------------------------------------ |\n",
    "| **Logic**               | Explicitly programmed rules        | Learns from data                           |\n",
    "| **Adaptability**        | Static behavior                    | Dynamic and improves over time             |\n",
    "| **Input/Output**        | Predictable output for known input | Output may vary depending on learned model |\n",
    "| **Development Process** | Rule-based coding                  | Model training and testing                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040c5fb",
   "metadata": {},
   "source": [
    "4. Provide examples of AI, ML, DL, and DS applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55afce7",
   "metadata": {},
   "source": [
    "AI: Chatbots (e.g., Siri, Alexa), autonomous vehicles\n",
    "\n",
    "ML: Email spam detection, fraud detection\n",
    "\n",
    "DL: Facial recognition, voice assistants\n",
    "\n",
    "DS: Business intelligence dashboards, customer behavior analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fbd795",
   "metadata": {},
   "source": [
    "5. Discuss the importance of AI, ML, DL, and DS in today's world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14473c",
   "metadata": {},
   "source": [
    "Automation: Reduces human effort in repetitive tasks.\n",
    "\n",
    "Personalization: Powers personalized recommendations (e.g., Netflix, Amazon).\n",
    "\n",
    "Healthcare: Enables early diagnosis through image analysis and data-driven treatment.\n",
    "\n",
    "Finance: Detects fraudulent transactions, improves investment strategies.\n",
    "\n",
    "Industry: Enhances efficiency, predictive maintenance, and quality control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acbfa8",
   "metadata": {},
   "source": [
    "6.  What is Supervised Learning\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19195987",
   "metadata": {},
   "source": [
    "Supervised Learning is a type of machine learning where the model is trained on labeled data. The algorithm learns the mapping between input features and known output labels to make future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd2b283",
   "metadata": {},
   "source": [
    "7. Provide examples of Supervised Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3382339",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Decision Trees\n",
    "\n",
    "Random Forest\n",
    "\n",
    "Support Vector Machines (SVM)\n",
    "\n",
    "k-Nearest Neighbors (k-NN)\n",
    "\n",
    "Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec6189c",
   "metadata": {},
   "source": [
    "8. Explain the process of Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766b9e5",
   "metadata": {},
   "source": [
    "1. Collect Data: Gather labeled training data.\n",
    "\n",
    "2. Preprocess Data: Clean and prepare data for the model.\n",
    "\n",
    "3. Split Data: Divide data into training and testing sets.\n",
    "\n",
    "4. Train Model: Use training data to teach the algorithm.\n",
    "\n",
    "5. Test Model: Evaluate performance using test data.\n",
    "\n",
    "6. Deploy Model: Use the trained model for predictions in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9815e2",
   "metadata": {},
   "source": [
    "9. What are the characteristics of Unsupervised Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84340805",
   "metadata": {},
   "source": [
    "No labeled output data.\n",
    "\n",
    "The model tries to find hidden patterns or structures.\n",
    "\n",
    "Common for clustering, dimensionality reduction, and anomaly detection.\n",
    "\n",
    "It discovers relationships in data without pre-defined labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d35576",
   "metadata": {},
   "source": [
    "10. Give examples of Unsupervised Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e98e8",
   "metadata": {},
   "source": [
    "k-Means Clustering\n",
    "\n",
    "Hierarchical Clustering\n",
    "\n",
    "Principal Component Analysis (PCA)\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering)\n",
    "\n",
    "Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82604cd",
   "metadata": {},
   "source": [
    "11. Describe Semi-Supervised Learning and its significance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d04f21",
   "metadata": {},
   "source": [
    "Semi-Supervised Learning is a type of machine learning that uses a small amount of labeled data along with a large amount of unlabeled data.\n",
    "It falls between Supervised and Unsupervised learning.\n",
    "\n",
    "Significance:\n",
    "\n",
    "Reduces the cost and effort of labeling large datasets.\n",
    "\n",
    "Often achieves higher accuracy than unsupervised learning when labeled data is scarce.\n",
    "\n",
    "Useful in domains like speech recognition, medical imaging, and natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acaa030",
   "metadata": {},
   "source": [
    "12.  Explain Reinforcement Learning and its applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb7601",
   "metadata": {},
   "source": [
    "Reinforcement Learning (RL) is a learning paradigm where an agent learns to make decisions by interacting with an environment. It receives rewards or penalties based on its actions and aims to maximize cumulative reward.\n",
    "\n",
    "Applications:\n",
    "\n",
    "Game AI (e.g., AlphaGo)\n",
    "\n",
    "Robotics (e.g., robot navigation)\n",
    "\n",
    "Self-driving cars\n",
    "\n",
    "Dynamic pricing\n",
    "\n",
    "Personalized recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400b6b7",
   "metadata": {},
   "source": [
    "13. How does Reinforcement Learning differ from Supervised and Unsupervised Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca63f4",
   "metadata": {},
   "source": [
    "| Feature      | Supervised Learning      | Unsupervised Learning | Reinforcement Learning                          |\n",
    "| ------------ | ------------------------ | --------------------- | ----------------------------------------------- |\n",
    "| **Data**     | Labeled                  | Unlabeled             | Based on interaction (states, actions, rewards) |\n",
    "| **Goal**     | Predict output           | Find hidden structure | Learn optimal strategy/policy                   |\n",
    "| **Feedback** | Correct answers provided | No feedback           | Delayed feedback (reward signals)               |\n",
    "| **Learning** | From examples            | From patterns         | From exploration and reward                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfce702",
   "metadata": {},
   "source": [
    "14.  What is the purpose of the Train-Test-Validation split in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac80405",
   "metadata": {},
   "source": [
    "The Train-Test-Validation split is used to:\n",
    "\n",
    "Train the model (training set)\n",
    "\n",
    "Validate it during tuning (validation set)\n",
    "\n",
    "Test final performance (testing set)\n",
    "\n",
    "It helps prevent overfitting, ensures generalization, and improves model reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568eee0",
   "metadata": {},
   "source": [
    "15.  Explain the significance of the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b9e18",
   "metadata": {},
   "source": [
    "The training set is the subset of data used to fit the model. It is crucial because:\n",
    "\n",
    "The model learns patterns, relationships, and weights from it.\n",
    "\n",
    "It directly influences how well the model can predict outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d16bf7",
   "metadata": {},
   "source": [
    "16.  How do you determine the size of the training, testing, and validation sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d25c8f",
   "metadata": {},
   "source": [
    "Commonly used split ratios:\n",
    "\n",
    "70% Train / 15% Validation / 15% Test\n",
    "\n",
    "80% Train / 10% Validation / 10% Test\n",
    "\n",
    "Factors to consider:\n",
    "\n",
    "Size of dataset\n",
    "\n",
    "Model complexity\n",
    "\n",
    "Need for reliable evaluation\n",
    "\n",
    "Balance between training quality and evaluation robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05451b",
   "metadata": {},
   "source": [
    "17.  What are the consequences of improper Train-Test-Validation splits?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e763769",
   "metadata": {},
   "source": [
    "Overfitting: Model performs well on training data but poorly on unseen data.\n",
    "\n",
    "Underfitting: Not enough training data leads to poor learning.\n",
    "\n",
    "Biased Evaluation: Using test data during training inflates performance metrics.\n",
    "\n",
    "Poor Generalization: Model may not work well in real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4fba4",
   "metadata": {},
   "source": [
    " 18. Discuss the trade-offs in selecting appropriate split ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58159b",
   "metadata": {},
   "source": [
    "More training data: Better learning but risk of weak evaluation.\n",
    "\n",
    "More test/validation data: Better evaluation but may reduce learning capacity.\n",
    "\n",
    "Small datasets: May need techniques like cross-validation instead of fixed splits.\n",
    "\n",
    "Goal: Balance between learning accuracy and evaluation reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92f69b",
   "metadata": {},
   "source": [
    "19.  Define model performance in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfec735",
   "metadata": {},
   "source": [
    "Model performance refers to how well a model makes predictions or classifies data. It is assessed based on its ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776ad35",
   "metadata": {},
   "source": [
    "20. How do you measure the performance of a machine learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab857352",
   "metadata": {},
   "source": [
    "Depends on task:\n",
    "\n",
    "1. Classification:\n",
    "\n",
    "    Accuracy\n",
    "\n",
    "    Precision, Recall, F1-Score\n",
    "\n",
    "    Confusion Matrix\n",
    "\n",
    "    ROC-AUC\n",
    "\n",
    "2. Regression:\n",
    "\n",
    "    Mean Squared Error (MSE)\n",
    "\n",
    "    Root Mean Squared Error (RMSE)\n",
    "\n",
    "    Mean Absolute Error (MAE)\n",
    "\n",
    "    R² Score\n",
    "\n",
    "3. General:\n",
    "\n",
    "    Cross-validation scores\n",
    "\n",
    "    Learning curves\n",
    "\n",
    "    Overfitting/underfitting analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b182ba5",
   "metadata": {},
   "source": [
    "21. What is overfitting and why is it problematic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b96f7d",
   "metadata": {},
   "source": [
    "Overfitting occurs when a machine learning model learns the training data too well, including its noise and outliers, and fails to generalize to new, unseen data.\n",
    "\n",
    "Why it's problematic:\n",
    "\n",
    "The model has high accuracy on training data but poor performance on test/real-world data.\n",
    "\n",
    "It leads to poor generalization, which defeats the purpose of predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12469c6",
   "metadata": {},
   "source": [
    "22. Provide techniques to address overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba731fa",
   "metadata": {},
   "source": [
    "Simplify the model (reduce complexity)\n",
    "\n",
    "Use more training data (if available)\n",
    "\n",
    "Cross-validation (e.g., k-fold)\n",
    "\n",
    "Regularization (e.g., L1/L2 penalties)\n",
    "\n",
    "Early stopping (especially in neural networks)\n",
    "\n",
    "Pruning (in decision trees)\n",
    "\n",
    "Dropout (for neural networks)\n",
    "\n",
    "Reduce training time or epoch count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f83d1",
   "metadata": {},
   "source": [
    "23. Explain underfitting and its implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556f224d",
   "metadata": {},
   "source": [
    "Underfitting occurs when a model is too simple to capture the underlying patterns in the data.\n",
    "\n",
    "Implications:\n",
    "\n",
    "    Poor performance on both training and test sets\n",
    "\n",
    "    Model fails to learn meaningful patterns\n",
    "\n",
    "    Results in high bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd3b76b",
   "metadata": {},
   "source": [
    "24. How can you prevent underfitting in machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4734e51",
   "metadata": {},
   "source": [
    "Increase model complexity (e.g., deeper trees, more layers)\n",
    "\n",
    "Train longer (more epochs or iterations)\n",
    "\n",
    "Feature engineering (include more relevant features)\n",
    "\n",
    "Reduce regularization (avoid over-penalizing complexity)\n",
    "\n",
    "Tune hyperparameters (e.g., learning rate, depth, number of neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385a82d",
   "metadata": {},
   "source": [
    "25.  Discuss the balance between bias and variance in model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e03ed",
   "metadata": {},
   "source": [
    "This is known as the bias-variance trade-off:\n",
    "\n",
    "Bias: Error due to overly simplistic models. High bias → Underfitting.\n",
    "\n",
    "Variance: Error due to too much complexity. High variance → Overfitting.\n",
    "\n",
    "Goal: Find a balance where both bias and variance are minimized:\n",
    "\n",
    "Too simple → high bias, low variance\n",
    "\n",
    "Too complex → low bias, high variance\n",
    "\n",
    "Ideal → low bias and low variance → optimal generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c2319",
   "metadata": {},
   "source": [
    "26.  What are the common techniques to handle missing data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a218b",
   "metadata": {},
   "source": [
    "Remove records with missing values (if few and not critical)\n",
    "\n",
    "Imputation:\n",
    "\n",
    "Mean/Median/Mode substitution\n",
    "\n",
    "Interpolation\n",
    "\n",
    "Predictive models (e.g., KNN, regression)\n",
    "\n",
    "Flag missing values as a separate category (for categorical data)\n",
    "\n",
    "Use algorithms that handle missing data internally (e.g., XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ce3e05",
   "metadata": {},
   "source": [
    "27.  Explain the implications of ignoring missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb926aa",
   "metadata": {},
   "source": [
    "Biased analysis and incorrect conclusions\n",
    "\n",
    "Reduced accuracy\n",
    "\n",
    "Loss of valuable information\n",
    "\n",
    "Data inconsistency and model errors\n",
    "\n",
    "Smaller dataset if rows/columns are dropped, reducing learning power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ad941d",
   "metadata": {},
   "source": [
    "28. Discuss the pros and cons of imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88691017",
   "metadata": {},
   "source": [
    "| Method                      | Pros                        | Cons                                                         |\n",
    "| --------------------------- | --------------------------- | ------------------------------------------------------------ |\n",
    "| **Mean/Median/Mode**        | Simple, fast                | Can distort data distribution; ignores feature relationships |\n",
    "| **KNN Imputation**          | Considers data similarity   | Computationally expensive; may not scale                     |\n",
    "| **Regression Imputation**   | Captures relationships      | Assumes linearity; can add bias                              |\n",
    "| **Multiple Imputation**     | Robust, statistically sound | Complex to implement; time-consuming                         |\n",
    "| **Dropping Missing Values** | Easy to do                  | Risk of information loss; reduces dataset size               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61526ba",
   "metadata": {},
   "source": [
    "29. How does missing data affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc561b54",
   "metadata": {},
   "source": [
    "Reduces model accuracy\n",
    "\n",
    "Increases uncertainty\n",
    "\n",
    "Can lead to biased or invalid predictions if not properly handled\n",
    "\n",
    "May cause models to fail to train if key features are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e485a272",
   "metadata": {},
   "source": [
    "30. Define imbalanced data in the context of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f7b14",
   "metadata": {},
   "source": [
    "Imbalanced data refers to datasets where classes are not represented equally, typically in classification problems (e.g., 95% negative, 5% positive).\n",
    "\n",
    "Why it matters:\n",
    "\n",
    "Models tend to favor the majority class\n",
    "\n",
    "Accuracy becomes misleading\n",
    "\n",
    "Critical in domains like fraud detection, disease diagnosis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f37fa5",
   "metadata": {},
   "source": [
    "31.  Discuss the challenges posed by imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab91886",
   "metadata": {},
   "source": [
    "Imbalanced data occurs when one class (usually the negative class) vastly outnumbers the other (positive class).\n",
    "\n",
    "Challenges:\n",
    "\n",
    "Biased models: Models may favor the majority class and ignore the minority.\n",
    "\n",
    "Misleading accuracy: A model may show high accuracy while failing to detect minority class.\n",
    "\n",
    "Poor recall/precision: Especially harmful in critical tasks like fraud detection or disease prediction.\n",
    "\n",
    "Inadequate training: The model doesn’t learn enough about the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f557d",
   "metadata": {},
   "source": [
    "32.  What techniques can be used to address imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b6cc4",
   "metadata": {},
   "source": [
    "1. Resampling:\n",
    "\n",
    "    Up-sampling the minority class\n",
    "\n",
    "    Down-sampling the majority class\n",
    "\n",
    "2. Synthetic Data Generation:\n",
    "\n",
    "    SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "3. Algorithmic Adjustments:\n",
    "\n",
    "    Use models with class weighting\n",
    "\n",
    "    Use cost-sensitive learning\n",
    "\n",
    "4. Evaluation Metric Changes:\n",
    "\n",
    "    Use F1-score, Precision, Recall, AUC instead of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bfe98c",
   "metadata": {},
   "source": [
    "33.  Explain the process of up-sampling and down-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5a392",
   "metadata": {},
   "source": [
    "Up-Sampling:\n",
    "\n",
    "Increases the number of minority class examples by duplicating existing samples or generating synthetic ones.\n",
    "\n",
    "Down-Sampling:\n",
    "\n",
    "Reduces the number of majority class examples by removing random samples to balance the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ee919",
   "metadata": {},
   "source": [
    "34.  When would you use up-sampling versus down-sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256f9e2",
   "metadata": {},
   "source": [
    "| Method            | When to Use                                                                                   |\n",
    "| ----------------- | --------------------------------------------------------------------------------------------- |\n",
    "| **Up-Sampling**   | When minority class is very small and you have **sufficient computing resources**.            |\n",
    "| **Down-Sampling** | When the dataset is very large and you want to **reduce training time** or avoid overfitting. |\n",
    "| **Both**          | Sometimes used together for better balance without sacrificing too much data.                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6d2c87",
   "metadata": {},
   "source": [
    "35.  What is SMOTE and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6030481",
   "metadata": {},
   "source": [
    "SMOTE (Synthetic Minority Over-sampling Technique) is a method to generate synthetic data points for the minority class.\n",
    "\n",
    "How it works:\n",
    "\n",
    "For each minority class sample, it finds its k-nearest neighbors.\n",
    "\n",
    "It selects one neighbor randomly.\n",
    "\n",
    "It creates a new synthetic sample along the line between the sample and neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ffe296",
   "metadata": {},
   "source": [
    "36.  Explain the role of SMOTE in handling imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c5db1",
   "metadata": {},
   "source": [
    "SMOTE helps to:\n",
    "\n",
    "    Balance the class distribution without duplicating data.\n",
    "\n",
    "    Improve model learning by exposing it to more representative minority class samples.\n",
    "\n",
    "    Avoid overfitting that can happen with simple duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f1deeb",
   "metadata": {},
   "source": [
    "37. Discuss the advantages and limitations of SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a593d",
   "metadata": {},
   "source": [
    "| Pros                                  | Cons                                                                        |\n",
    "| ------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| Reduces overfitting                   | Can introduce noise if minority class is noisy                              |\n",
    "| Generates more diverse examples       | May create overlapping classes                                              |\n",
    "| Works better than random oversampling | Not effective if dataset is high-dimensional or has small minority clusters |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4a12a",
   "metadata": {},
   "source": [
    "38. Provide examples of scenarios where SMOTE is beneficial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c6a98",
   "metadata": {},
   "source": [
    "Medical Diagnosis: Where disease cases are rare compared to healthy samples.\n",
    "\n",
    "Fraud Detection: Fraudulent transactions are far fewer than legitimate ones.\n",
    "\n",
    "Spam Filtering: Spam messages are typically outnumbered by normal emails.\n",
    "\n",
    "Customer Churn Prediction: Fewer customers actually leave compared to those who stay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a494090",
   "metadata": {},
   "source": [
    "39.  Define data interpolation and its purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0bcd9a",
   "metadata": {},
   "source": [
    "Data interpolation is the process of estimating missing or unknown values within the range of known data points.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "To fill in missing values in time series or numerical data\n",
    "\n",
    "To ensure data continuity and smoothness\n",
    "\n",
    "To support visualization or model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045bbc4",
   "metadata": {},
   "source": [
    "40. What are the common methods of data interpolation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a7e3b",
   "metadata": {},
   "source": [
    "Linear Interpolation: Connects two known values with a straight line\n",
    "\n",
    "Polynomial Interpolation: Uses polynomial functions for curve fitting\n",
    "\n",
    "Spline Interpolation: Fits smooth curves between points (cubic spline is common)\n",
    "\n",
    "Nearest-Neighbor Interpolation: Uses the value of the nearest known point\n",
    "\n",
    "Time-based Interpolation: Often used in time series data to infer missing timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de968d",
   "metadata": {},
   "source": [
    "41.  Discuss the implications of using data interpolation in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76932b",
   "metadata": {},
   "source": [
    "Data interpolation is used to estimate unknown values between known data points.\n",
    "\n",
    "Implications:\n",
    "\n",
    "✅ Positive:\n",
    "\n",
    "Helps fill in missing data, making models more robust.\n",
    "\n",
    "Useful in time series to maintain continuity.\n",
    "\n",
    "Reduces data loss and preserves trends in small datasets.\n",
    "\n",
    "⚠️ Negative:\n",
    "\n",
    "Introduces bias if the interpolation does not represent real trends.\n",
    "\n",
    "Can lead to overfitting if interpolated values are treated as true observations.\n",
    "\n",
    "Might misrepresent variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26338805",
   "metadata": {},
   "source": [
    "42.  What are outliers in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17db253d",
   "metadata": {},
   "source": [
    "Outliers are data points that deviate significantly from other observations in the dataset.\n",
    "They may be due to:\n",
    "\n",
    "Measurement errors\n",
    "\n",
    "Data entry errors\n",
    "\n",
    "True variability in the data (e.g., rare events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77922aaa",
   "metadata": {},
   "source": [
    "43.  Explain the impact of outliers on machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301f3ea",
   "metadata": {},
   "source": [
    "    Skew model predictions (especially in regression and mean-based algorithms).\n",
    "\n",
    "    Increase error rate in models sensitive to distance (e.g., KNN, SVM).\n",
    "\n",
    "    Affect convergence in optimization algorithms like gradient descent.\n",
    "\n",
    "    However, in some domains (fraud detection), outliers are meaningful and should not be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5137eb",
   "metadata": {},
   "source": [
    "44.  Discuss techniques for identifying outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1fa64",
   "metadata": {},
   "source": [
    "    Statistical methods:\n",
    "\n",
    "Z-score (|Z| > 3 often indicates an outlier)\n",
    "\n",
    "IQR method (values outside 1.5 * IQR are outliers)\n",
    "\n",
    "    Visualization:\n",
    "\n",
    "Box plots\n",
    "\n",
    "Scatter plots\n",
    "\n",
    "Histogram\n",
    "\n",
    "    Model-based methods:\n",
    "\n",
    "Isolation Forest\n",
    "\n",
    "One-Class SVM\n",
    "\n",
    "DBSCAN clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34244985",
   "metadata": {},
   "source": [
    "45. How can outliers be handled in a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4969a04",
   "metadata": {},
   "source": [
    "    Remove: If caused by error and not representative.\n",
    "\n",
    "    Cap/Floor (Winsorization): Limit values to a certain range.\n",
    "\n",
    "    Transform: Use log/square root to reduce skewness.\n",
    "\n",
    "    Impute: Replace with mean/median if appropriate.\n",
    "\n",
    "    Model Adjustment: Use models robust to outliers (e.g., tree-based models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f24c2",
   "metadata": {},
   "source": [
    "46.  Compare and contrast Filter, Wrapper, and Embedded methods for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5dbc52",
   "metadata": {},
   "source": [
    "| Method       | Description                                     | Evaluation Criterion          |\n",
    "| ------------ | ----------------------------------------------- | ----------------------------- |\n",
    "| **Filter**   | Select features based on statistical measures   | Independent of ML model       |\n",
    "| **Wrapper**  | Select features by evaluating model performance | Uses ML model to test subsets |\n",
    "| **Embedded** | Feature selection during model training         | Built into model algorithm    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d767d5",
   "metadata": {},
   "source": [
    "47.  Provide examples of algorithms associated with each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cd1eda",
   "metadata": {},
   "source": [
    "    Filter:\n",
    "\n",
    "Chi-square test\n",
    "\n",
    "Mutual information\n",
    "\n",
    "Pearson correlation\n",
    "\n",
    "    Wrapper:\n",
    "\n",
    "Recursive Feature Elimination (RFE)\n",
    "\n",
    "Forward/Backward Selection\n",
    "\n",
    "    Embedded:\n",
    "\n",
    "LASSO (L1 Regularization)\n",
    "\n",
    "Decision Trees (e.g., feature importance from Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643bb438",
   "metadata": {},
   "source": [
    "48.  Discuss the advantages and disadvantages of each feature selection method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6093d",
   "metadata": {},
   "source": [
    "| Method       | Advantages                                        | Disadvantages                                   |\n",
    "| ------------ | ------------------------------------------------- | ----------------------------------------------- |\n",
    "| **Filter**   | Fast, model-agnostic, simple                      | Ignores feature interaction with model          |\n",
    "| **Wrapper**  | Better performance, considers feature interaction | Computationally expensive, prone to overfitting |\n",
    "| **Embedded** | Efficient, model-aware, balances accuracy/speed   | Model-specific, less generalizable              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d47884",
   "metadata": {},
   "source": [
    "49.  Explain the concept of feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ac8f5",
   "metadata": {},
   "source": [
    "Feature scaling is the process of normalizing or standardizing independent variables to a common scale.\n",
    "It's crucial for algorithms that are sensitive to the scale of data, such as:\n",
    "\n",
    "KNN, SVM, Gradient Descent-based models, PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78bdaa",
   "metadata": {},
   "source": [
    "50.  Describe the process of standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea269747",
   "metadata": {},
   "source": [
    "Standardization transforms data to have:\n",
    "\n",
    "Mean = 0\n",
    "\n",
    "Standard Deviation = 1\n",
    "\n",
    "Formula:\n",
    "\n",
    "𝑧 = (𝑥−𝜇)/𝜎\n",
    "\n",
    "​ \n",
    "Where:\n",
    "\n",
    "x is the original value\n",
    "\n",
    "μ is the mean\n",
    "\n",
    "σ is the standard deviation\n",
    "\n",
    "This process helps models treat all features equally and improves convergence in optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ea1b1",
   "metadata": {},
   "source": [
    "51.  How does mean normalization differ from standardization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5225d",
   "metadata": {},
   "source": [
    "    Mean Normalization:\n",
    "Scales data so that its mean becomes 0 and the values are in the range [-1, 1].\n",
    "Formula:\n",
    "\n",
    "x′ = x−μ / max−min\n",
    "\n",
    "​\n",
    " \n",
    "    Standardization (Z-score normalization):\n",
    "Scales data to have mean = 0 and standard deviation = 1.\n",
    "Formula:\n",
    "\n",
    "x′ = x−μ/σ\n",
    "\n",
    "​\n",
    " \n",
    "Key difference:\n",
    "\n",
    "    Mean normalization uses the data range.\n",
    "\n",
    "    Standardization uses standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f105f3",
   "metadata": {},
   "source": [
    "52.  Discuss the advantages and disadvantages of Min-Max scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c015ec4",
   "metadata": {},
   "source": [
    "    Advantages:\n",
    "\n",
    "Preserves relationships and relative distances between values.\n",
    "\n",
    "Keeps values within a bounded range [0, 1], making it suitable for algorithms like neural networks and gradient descent.\n",
    "\n",
    "    Disadvantages:\n",
    "\n",
    "Sensitive to outliers – a single large or small value can skew the scaling.\n",
    "\n",
    "Not robust; requires all data to be known in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f28267",
   "metadata": {},
   "source": [
    "53.  What is the purpose of unit vector scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758b640",
   "metadata": {},
   "source": [
    "Unit vector scaling (also called normalization) rescales a feature vector so that its length (or norm) is 1.\n",
    "Formula (L2 Norm):\n",
    "\n",
    "x′ = x/∥x∥2\n",
    "​\n",
    " \n",
    "Purpose:\n",
    "\n",
    "Ensures equal contribution of each feature.\n",
    "\n",
    "Useful in text classification, KNN, and cosine similarity-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1390c",
   "metadata": {},
   "source": [
    "54.  Define Principle Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a0362",
   "metadata": {},
   "source": [
    "PCA is a dimensionality reduction technique that transforms a high-dimensional dataset into a lower-dimensional space by finding new orthogonal axes (principal components) that capture maximum variance in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f5f1b",
   "metadata": {},
   "source": [
    "55. Explain the steps involved in PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5263993",
   "metadata": {},
   "source": [
    "1. Standardize the dataset.\n",
    "\n",
    "2. Compute covariance matrix.\n",
    "\n",
    "3. Calculate eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "4. Sort eigenvectors by decreasing eigenvalues.\n",
    "\n",
    "5. Select top k eigenvectors (principal components).\n",
    "\n",
    "6. Transform the data into the new lower-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf375be",
   "metadata": {},
   "source": [
    "56.  Discuss the significance of eigenvalues and eigenvectors in PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bfe4e",
   "metadata": {},
   "source": [
    "Eigenvectors: Define the direction of new axes (principal components).\n",
    "\n",
    "Eigenvalues: Indicate the amount of variance captured by each principal component.\n",
    "\n",
    "→ Larger eigenvalue = more important component\n",
    "→ They help in ranking components to choose top k dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872b740",
   "metadata": {},
   "source": [
    "57.  How does PCA help in dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2636f4",
   "metadata": {},
   "source": [
    "PCA projects data onto a smaller set of orthogonal axes (principal components) that capture the most variance.\n",
    "\n",
    "It removes redundant features, reduces noise, and speeds up model training while retaining most of the important information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a926fce",
   "metadata": {},
   "source": [
    "58.  Define data encoding and its importance in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7abf573",
   "metadata": {},
   "source": [
    "Data encoding is the process of converting categorical data into numerical format so that it can be used in machine learning algorithms.\n",
    "\n",
    "Importance:\n",
    "\n",
    "Many ML models (e.g., linear regression, SVM) require numerical input.\n",
    "\n",
    "Helps models interpret and learn from categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653c977",
   "metadata": {},
   "source": [
    "59.  Explain Nominal Encoding and provide an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1157d02",
   "metadata": {},
   "source": [
    "Nominal Encoding (a.k.a. Label Encoding) assigns an integer to each category in a feature.\n",
    "Used for non-ordinal categorical data.\n",
    "\n",
    "Example:\n",
    "\n",
    "    Color: Red, Green, Blue → Red=0, Green=1, Blue=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7f4dd",
   "metadata": {},
   "source": [
    "60. Discuss the process of One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f4204",
   "metadata": {},
   "source": [
    "One Hot Encoding creates binary columns for each category in a feature. Each row has a 1 in the column corresponding to its category, and 0 elsewhere.\n",
    "\n",
    "Example:\n",
    "\n",
    "    Color: Red, Green, Blue  \n",
    "    → Red  → [1, 0, 0]  \n",
    "    → Green→ [0, 1, 0]  \n",
    "    → Blue → [0, 0, 1]\n",
    "\n",
    "Prevents models from interpreting categories as ordinal.\n",
    "\n",
    "Increases dimensionality (especially with many categories).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cde753",
   "metadata": {},
   "source": [
    " 61. How do you handle multiple categories in One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f895883f",
   "metadata": {},
   "source": [
    "When a feature has many categories, One Hot Encoding can create a large number of columns, leading to:\n",
    "\n",
    "High dimensionality\n",
    "\n",
    "Increased memory usage\n",
    "\n",
    "Sparsity of data\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Limit top categories and group rare ones as \"Other\"\n",
    "\n",
    "Feature hashing to reduce dimensionality\n",
    "\n",
    "Embedding techniques for high-cardinality data (especially in deep learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17039818",
   "metadata": {},
   "source": [
    " 62. Explain Mean Encoding and its advantages\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9a5cb",
   "metadata": {},
   "source": [
    "Mean Encoding replaces each category with the mean of the target variable for that category.\n",
    "\n",
    "    Example:\n",
    "| City   | Avg Purchase (Target) |\n",
    "| ------ | --------------------- |\n",
    "| Delhi  | 2000                  |\n",
    "| Mumbai | 1500                  |\n",
    "\n",
    "    Encoded:\n",
    "City: Delhi → 2000, Mumbai → 1500\n",
    "\n",
    "    Advantages:\n",
    "\n",
    "Captures target-category relationship\n",
    "\n",
    "Low-dimensional, unlike One Hot Encoding\n",
    "\n",
    "Useful for tree-based models\n",
    "\n",
    "    Caution: Can lead to target leakage → use techniques like K-fold mean encoding to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2db1ff",
   "metadata": {},
   "source": [
    "63. Provide examples of Ordinal Encoding and Label Encoding\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f2e20",
   "metadata": {},
   "source": [
    "    Ordinal Encoding: Used for ordered categories\n",
    "Education: High School = 1, Bachelor = 2, Master = 3, PhD = 4\n",
    "\n",
    "    Label Encoding: Used for nominal data (no order), but still assigns integers\n",
    "Color: Red = 0, Green = 1, Blue = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354af85",
   "metadata": {},
   "source": [
    "64. What is Target Guided Ordinal Encoding and how is it used\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059fc064",
   "metadata": {},
   "source": [
    "In Target Guided Ordinal Encoding, categories are ranked based on the mean of the target variable, and then assigned ordered integers.\n",
    "\n",
    "    Steps:\n",
    "\n",
    "Calculate mean target per category.\n",
    "\n",
    "Sort categories by this mean.\n",
    "\n",
    "Assign integers accordingly.\n",
    "\n",
    "    Example:\n",
    "| Category | Avg Target |\n",
    "| -------- | ---------- |\n",
    "| C        | 10         |\n",
    "| A        | 20         |\n",
    "| B        | 30         |\n",
    "\n",
    "    Encoded:\n",
    "C = 0, A = 1, B = 2\n",
    "\n",
    "    Useful for models that benefit from ordinal information\n",
    "    Needs to be handled carefully to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f509194",
   "metadata": {},
   "source": [
    "65. Define covariance and its significance in statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4312c",
   "metadata": {},
   "source": [
    "Covariance measures the directional relationship between two variables.\n",
    "\n",
    "    Formula:\n",
    "\n",
    "Cov(X,Y)= ∑(xi − ˉxˉ)(yi − ˉyˉ)/n−1\n",
    "\n",
    "​ \n",
    "Positive covariance → variables increase together\n",
    "\n",
    "Negative covariance → one increases while the other decreases\n",
    "\n",
    "    Significance:\n",
    "\n",
    "Helps identify linear relationships\n",
    "\n",
    "Used in PCA and portfolio risk analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150eeb3",
   "metadata": {},
   "source": [
    " 66. Explain the process of correlation check\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bbb06b",
   "metadata": {},
   "source": [
    "A correlation check helps find relationships between features, typically using Pearson or Spearman methods.\n",
    "\n",
    "    Steps:\n",
    "\n",
    "Choose correlation method (e.g., Pearson, Spearman)\n",
    "\n",
    "Compute correlation matrix\n",
    "\n",
    "Visualize using heatmap (optional)\n",
    "\n",
    "Drop one of two features with high correlation (e.g., > 0.8)\n",
    "\n",
    "    Helps avoid multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10405e3",
   "metadata": {},
   "source": [
    "67. What is the Pearson Correlation Coefficient\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e73bc",
   "metadata": {},
   "source": [
    "The Pearson Correlation Coefficient (r) measures the linear relationship between two variables.\n",
    "\n",
    "    Formula:\n",
    "\n",
    "𝑟 = Cov(X,Y)/σX σY\n",
    "​\n",
    " \n",
    "    Range: −1 to +1\n",
    "\n",
    "+1 → perfect positive linear correlation\n",
    "\n",
    "-1 → perfect negative linear correlation\n",
    "\n",
    "0 → no linear correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfff129",
   "metadata": {},
   "source": [
    "68. How does Spearman's Rank Correlation differ from Pearson's Correlation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ec4f8",
   "metadata": {},
   "source": [
    "| Feature             | Pearson                           | Spearman                             |\n",
    "| ------------------- | --------------------------------- | ------------------------------------ |\n",
    "| Type                | Measures **linear** relationships | Measures **monotonic** relationships |\n",
    "| Assumptions         | Requires **normal distribution**  | **No assumption** of distribution    |\n",
    "| Data Handling       | Uses raw values                   | Uses **ranks**                       |\n",
    "| Outlier Sensitivity | Sensitive                         | Less sensitive                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e075c5",
   "metadata": {},
   "source": [
    "69. Discuss the importance of Variance Inflation Factor (VIF) in feature selection\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f043cec",
   "metadata": {},
   "source": [
    "VIF quantifies how much a feature is correlated with other features (i.e., multicollinearity).\n",
    "\n",
    "    Formula:\n",
    "\n",
    "VIF= 1/1−R^2\n",
    "\n",
    "VIF > 5 or 10 → high multicollinearity → consider removing the feature.\n",
    "\n",
    "    Helps improve model interpretability\n",
    "    Mostly used for linear regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380718d",
   "metadata": {},
   "source": [
    "70. Define feature selection and its purpose\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680409ed",
   "metadata": {},
   "source": [
    "Feature selection is the process of selecting the most relevant features from a dataset for use in model building.\n",
    "\n",
    "    Purpose:\n",
    "\n",
    "Improve model performance and accuracy\n",
    "\n",
    "Reduce overfitting\n",
    "\n",
    "Shorten training time\n",
    "\n",
    "Enhance interpretability\n",
    "\n",
    "    Feature selection can be done via:\n",
    "\n",
    "Filter methods (e.g., correlation)\n",
    "\n",
    "Wrapper methods (e.g., RFE)\n",
    "\n",
    "Embedded methods (e.g., LASSO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca8007",
   "metadata": {},
   "source": [
    "71. Explain the process of Recursive Feature Elimination\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd6400",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE) is a wrapper-based feature selection technique that recursively removes the least important features.\n",
    "\n",
    "    Process:\n",
    "\n",
    "1. Choose a base model (e.g., linear regression, decision tree).\n",
    "\n",
    "2. Train the model on the full feature set.\n",
    "\n",
    "3. Rank features by importance (e.g., coefficients or impurity).\n",
    "\n",
    "4. Remove the least important feature(s).\n",
    "\n",
    "5. Repeat until the desired number of features is reached.\n",
    "\n",
    "        Finds optimal subset of features\n",
    "        Computationally expensive for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db859554",
   "metadata": {},
   "source": [
    "72. How does Backward Elimination work\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f279a6",
   "metadata": {},
   "source": [
    "Backward Elimination starts with all features, and iteratively removes the least significant one based on a metric (e.g., p-value, feature importance).\n",
    "\n",
    "    Steps:\n",
    "\n",
    "1. Train model on all features.\n",
    "\n",
    "2. Evaluate significance of each feature.\n",
    "\n",
    "3. Remove the least significant one.\n",
    "\n",
    "4. Repeat until all remaining features are significant.\n",
    "\n",
    "        Simple, interpretable\n",
    "\n",
    "        May miss combinations of weakly significant but useful features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c297e",
   "metadata": {},
   "source": [
    "73. Discuss the advantages and limitations of Forward Elimination\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35582fbf",
   "metadata": {},
   "source": [
    "    Advantages:\n",
    "\n",
    "Starts from nothing → prevents unnecessary complexity.\n",
    "\n",
    "Faster than backward elimination with many features.\n",
    "\n",
    "Useful when model training is expensive.\n",
    "\n",
    "    Limitations:\n",
    "\n",
    "Greedy: might miss optimal feature combinations.\n",
    "\n",
    "Sensitive to the initial selection.\n",
    "\n",
    "May stop too early due to local optima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f4af9",
   "metadata": {},
   "source": [
    "74. What is feature engineering and why is it important\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d56687d",
   "metadata": {},
   "source": [
    "Feature Engineering is the process of creating, transforming, or selecting features to improve model performance.\n",
    "\n",
    "    Importance:\n",
    "\n",
    "Increases accuracy and efficiency\n",
    "\n",
    "Helps models learn patterns more easily\n",
    "\n",
    "Bridges gap between raw data and machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b01eaf",
   "metadata": {},
   "source": [
    "75. Discuss the steps involved in feature engineering\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737e68f",
   "metadata": {},
   "source": [
    "1. Understand the data: Explore data types, distributions, and domain context.\n",
    "\n",
    "2. Handle missing values: Imputation or removal.\n",
    "\n",
    "3. Encode categorical variables: One-Hot, Label, Target encoding.\n",
    "\n",
    "4. Create new features: Ratios, differences, time-based features.\n",
    "\n",
    "5. Scale/normalize: StandardScaler, MinMaxScaler, etc.\n",
    "\n",
    "6. Transform: Log, square root, Box-Cox, etc.\n",
    "\n",
    "7. Reduce dimensions (if needed): PCA, t-SNE.\n",
    "\n",
    "8. Select features: Use filter/wrapper/embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0400af",
   "metadata": {},
   "source": [
    "76. Provide examples of feature engineering techniques\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1282f",
   "metadata": {},
   "source": [
    "Binning: Grouping numerical values (e.g., age → age groups)\n",
    "\n",
    "Date decomposition: Extracting year/month/day from datetime\n",
    "\n",
    "Interaction terms: feature1 * feature2\n",
    "\n",
    "Aggregations: Mean, sum, count per group\n",
    "\n",
    "Log transforms: To reduce skewness\n",
    "\n",
    "Text vectorization: TF-IDF, word embeddings for text data\n",
    "\n",
    "Polynomial features: Adding squared or interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e5238",
   "metadata": {},
   "source": [
    "77. How does feature selection differ from feature engineering\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6caa2",
   "metadata": {},
   "source": [
    "| Aspect         | Feature Selection                    | Feature Engineering                       |\n",
    "| -------------- | ------------------------------------ | ----------------------------------------- |\n",
    "| **Definition** | Choosing the best subset of features | Creating/modifying new features           |\n",
    "| **Purpose**    | Reduce redundancy/noise              | Extract meaningful information            |\n",
    "| **Output**     | Subset of existing features          | Enhanced/new feature set                  |\n",
    "| **Examples**   | RFE, LASSO, Chi-Square               | Log transform, datetime split, NLP TF-IDF |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c72b72",
   "metadata": {},
   "source": [
    "78. Explain the importance of feature selection in machine learning pipelines\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08416a30",
   "metadata": {},
   "source": [
    "Reduces overfitting\n",
    "\n",
    "Enhances model accuracy\n",
    "\n",
    "Decreases training time\n",
    "\n",
    "Improves interpretability\n",
    "\n",
    "Reduces dimensionality, helping in visualization and debugging\n",
    "\n",
    "    Essential step before modeling in automated ML pipelines (like sklearn's Pipeline, FeatureUnion)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e90f7a",
   "metadata": {},
   "source": [
    "79. Discuss the impact of feature selection on model performance\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569b882",
   "metadata": {},
   "source": [
    "Improves generalization by removing noise\n",
    "\n",
    "Speeds up training and inference\n",
    "\n",
    "Helps models focus on relevant patterns\n",
    "\n",
    "Too aggressive selection may remove useful information, hurting performance\n",
    "\n",
    "→ Balance is key: avoid both under- and over-selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1de8ad",
   "metadata": {},
   "source": [
    "80. How do you determine which features to include in a machine-learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6f23c",
   "metadata": {},
   "source": [
    "    Approaches:\n",
    "\n",
    "1. Statistical techniques: Correlation, ANOVA, Chi-square\n",
    "\n",
    "2. Model-based importance: Tree-based models, LASSO\n",
    "\n",
    "3. Domain knowledge: Expert insight\n",
    "\n",
    "4. Automated methods:\n",
    "\n",
    "    Recursive Feature Elimination (RFE)\n",
    "\n",
    "    SHAP or Permutation Importance\n",
    "\n",
    "5. Validation performance: Compare model scores (accuracy, RMSE, F1) with different feature subsets using cross-validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
