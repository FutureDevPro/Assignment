{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f1e778",
   "metadata": {},
   "source": [
    "1. Explain the architecture of LeNet-5 and its significance in the field of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606518a7",
   "metadata": {},
   "source": [
    "**Architecture and Its Significance**\n",
    "\n",
    "**Overview**\n",
    "\n",
    "LeNet-5 is a convolutional neural network (CNN) developed by Yann LeCun et al. in 1998 for handwritten digit recognition (e.g., MNIST dataset). It is one of the first CNN architectures, foundational for modern deep learning in computer vision.\n",
    "\n",
    "**LeNet-5 Architecture**\n",
    "\n",
    "    LeNet-5 takes a 32Ã—32 grayscale image as input and passes it through a series of convolutional, pooling, and fully connected layers. Here's the layer-wise breakdown:\n",
    "\n",
    "| Layer      | Type                                      | Parameters                                        | Output Size |\n",
    "| ---------- | ----------------------------------------- | ------------------------------------------------- | ----------- |\n",
    "| **Input**  | â€”                                         | 32Ã—32 grayscale image                             | 32Ã—32Ã—1     |\n",
    "| **C1**     | Convolutional                             | 6 filters of size 5Ã—5, stride 1                   | 28Ã—28Ã—6     |\n",
    "| **S2**     | Subsampling (Avg Pooling)                 | 2Ã—2 pooling, stride 2                             | 14Ã—14Ã—6     |\n",
    "| **C3**     | Convolutional                             | 16 filters (some connected to subsets of S2 maps) | 10Ã—10Ã—16    |\n",
    "| **S4**     | Subsampling (Avg Pooling)                 | 2Ã—2 pooling, stride 2                             | 5Ã—5Ã—16      |\n",
    "| **C5**     | Convolutional (Fully connected in nature) | 120 filters of size 5Ã—5                           | 1Ã—1Ã—120     |\n",
    "| **F6**     | Fully Connected                           | 120 to 84                                         | 84          |\n",
    "| **Output** | Fully Connected                           | 84 to 10 (for classification)                     | 10          |\n",
    "\n",
    "\n",
    " Activation function: tanh or sigmoid was used traditionally\n",
    " No ReLU or BatchNorm â€“ those came later in modern CNNs\n",
    "\n",
    "**Architecture Summary Diagram (Simplified)**\n",
    "\n",
    "Input (32x32)\n",
    "\n",
    "   â†“\n",
    "\n",
    "C1: Conv (5x5, 6 filters) â†’ 28x28x6\n",
    "\n",
    "   â†“\n",
    "\n",
    "S2: AvgPool (2x2) â†’ 14x14x6\n",
    "\n",
    "   â†“\n",
    "\n",
    "C3: Conv (5x5, 16 filters) â†’ 10x10x16\n",
    "\n",
    "   â†“\n",
    "\n",
    "S4: AvgPool (2x2) â†’ 5x5x16\n",
    "\n",
    "   â†“\n",
    "\n",
    "C5: Conv (5x5, 120 filters) â†’ 1x1x120\n",
    "\n",
    "   â†“\n",
    "\n",
    "F6: Fully Connected â†’ 84\n",
    "\n",
    "   â†“\n",
    "   \n",
    "Output Layer â†’ 10 classes (digits 0â€“9)\n",
    "\n",
    "**Significance of LeNet-5 in Deep Learning**\n",
    "\n",
    "1. Foundation of CNNs\n",
    "\n",
    "    LeNet-5 introduced the core ideas that are now standard in CNNs:\n",
    "\n",
    "Local receptive fields (convolution)\n",
    "\n",
    "Parameter sharing\n",
    "\n",
    "Pooling (downsampling)\n",
    "\n",
    "Hierarchical feature extraction\n",
    "\n",
    "2. Real-world Application\n",
    "\n",
    "It showed CNNs could outperform traditional methods on practical tasks like digit recognition, laying the groundwork for more complex tasks (e.g., object detection, face recognition).\n",
    "\n",
    "3. Shift from Handcrafted Features to End-to-End Learning\n",
    "\n",
    "Before LeNet-5, most models used manually engineered features (SIFT, HOG). LeNet learned features automatically from raw pixels, which is the essence of modern deep learning.\n",
    "\n",
    "4. Inspired Modern Architectures\n",
    "\n",
    "    It inspired modern CNNs like:\n",
    "\n",
    "AlexNet (2012)\n",
    "\n",
    "VGGNet\n",
    "\n",
    "GoogLeNet\n",
    "\n",
    "ResNet\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "Designed for simple grayscale images (not robust to high-resolution color images)\n",
    "\n",
    "No use of ReLU, dropout, or batch normalization\n",
    "\n",
    "Lacks depth and scalability\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "LeNet-5 is a pioneer in deep learning for vision tasks. While outdated by modern standards, it introduced fundamental principles that shaped today's deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821dc71",
   "metadata": {},
   "source": [
    "2.  Describe the key components of LeNet-5 and their roles in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bc5a2",
   "metadata": {},
   "source": [
    "**1. Input Layer**\n",
    "\n",
    "Input size: 32Ã—32 grayscale image\n",
    "\n",
    "Role: Takes raw pixel values. MNIST images (28Ã—28) are often zero-padded to 32Ã—32.\n",
    "\n",
    "Why 32x32? It provides room for convolution and pooling operations without shrinking the feature map too quickly.\n",
    "\n",
    "**2. C1 â€” Convolutional Layer**\n",
    "\n",
    "Details: 6 filters, each 5Ã—5, stride = 1\n",
    "\n",
    "Output: 28Ã—28Ã—6\n",
    "\n",
    "Role:\n",
    "\n",
    "Detects low-level features like edges, corners.\n",
    "\n",
    "Each filter scans across the image and produces a feature map.\n",
    "\n",
    "Activation: Tanh or sigmoid (originally)\n",
    "\n",
    "**3. S2 â€” Subsampling Layer (Average Pooling)**\n",
    "\n",
    "Details: 2Ã—2 pooling with stride 2\n",
    "\n",
    "Output: 14Ã—14Ã—6\n",
    "\n",
    "Role:\n",
    "\n",
    "Downsamples feature maps, reducing spatial size.\n",
    "\n",
    "Provides translation invariance (helps recognize digits even if slightly shifted).\n",
    "\n",
    "Reduces overfitting and computational complexity.\n",
    "\n",
    "**4. C3 â€” Convolutional Layer**\n",
    "\n",
    "Details: 16 filters, 5Ã—5, selective connections to previous maps\n",
    "\n",
    "Output: 10Ã—10Ã—16\n",
    "\n",
    "Role:\n",
    "\n",
    "Extracts higher-level features from the pooled maps.\n",
    "\n",
    "Not all filters are connected to all previous maps â€” this reduces parameters and mimics biological vision systems.\n",
    "\n",
    "**5. S4 â€” Subsampling Layer (Average Pooling)**\n",
    "\n",
    "Details: 2Ã—2 pooling, stride 2\n",
    "\n",
    "Output: 5Ã—5Ã—16\n",
    "\n",
    "Role:\n",
    "\n",
    "Further downsampling.\n",
    "\n",
    "Makes features more compact and abstract.\n",
    "\n",
    "Continues translation invariance.\n",
    "\n",
    "**6. C5 â€” Convolutional Layer (Fully Connected in Nature)**\n",
    "\n",
    "Details: 120 filters, each 5Ã—5\n",
    "\n",
    "Input: 5Ã—5Ã—16 feature maps â†’ Each 5Ã—5Ã—16 volume is connected to one neuron\n",
    "\n",
    "Output: 120Ã—1\n",
    "\n",
    "Role:\n",
    "\n",
    "Acts as a fully connected layer though it's implemented as a convolution.\n",
    "\n",
    "Transitions from spatial feature extraction to dense representation.\n",
    "\n",
    "Learns global features of the image.\n",
    "\n",
    "**7. F6 â€” Fully Connected Layer**\n",
    "\n",
    "Details: 120 â†’ 84\n",
    "\n",
    "Role:\n",
    "\n",
    "Dense connections like traditional neural nets.\n",
    "\n",
    "Prepares features for classification.\n",
    "\n",
    "Captures abstract combinations of high-level features.\n",
    "\n",
    "**8. Output Layer**\n",
    "\n",
    "Details: 84 â†’ 10 (for digits 0â€“9)\n",
    "\n",
    "Role:\n",
    "\n",
    "Final classification layer.\n",
    "\n",
    "Outputs a probability score (via softmax) for each digit class.\n",
    "\n",
    "**Summary of Component Roles:**\n",
    "\n",
    "| Component                    | Role                                            |\n",
    "| ---------------------------- | ----------------------------------------------- |\n",
    "| **Convolution (C1, C3, C5)** | Extract features (from low-level to high-level) |\n",
    "| **Subsampling (S2, S4)**     | Downsample spatial size, provide invariance     |\n",
    "| **Fully Connected (F6)**     | Combine abstracted features                     |\n",
    "| **Output Layer**             | Predict final class (digit)                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343e952",
   "metadata": {},
   "source": [
    "3.  Discuss the limitations of LeNet-5 and how subsequent architectures like AlexNet addressed these \n",
    "limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d3f74",
   "metadata": {},
   "source": [
    "**Limitations of LeNet-5 and How AlexNet Addressed Them**\n",
    "\n",
    "**Limitations of LeNet-5**\n",
    "\n",
    "| Limitation                          | Description                                                                                                                          |\n",
    "| ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **1. Small-scale input**            | Designed for 32Ã—32 grayscale images (MNIST); not suitable for real-world high-resolution, colored images (e.g., ImageNet 224Ã—224Ã—3). |\n",
    "| **2. Shallow architecture**         | Only 7 layers (including FC layers); unable to extract complex patterns or hierarchical features in large datasets.                  |\n",
    "| **3. Tanh activation function**     | Uses `tanh` or `sigmoid` which suffer from **vanishing gradient** and slower training.                                               |\n",
    "| **4. No use of GPUs**               | Originally designed for CPU; training was slow and didnâ€™t scale to large datasets.                                                   |\n",
    "| **5. No dropout or regularization** | Lacks techniques to prevent overfitting on large, complex datasets.                                                                  |\n",
    "| **6. Limited to specific domains**  | Effective only on tasks like digit recognition, not general-purpose object classification.                                           |\n",
    "| **7. No data augmentation**         | Doesn't use techniques to artificially increase training data variability.                                                           |\n",
    "\n",
    "\n",
    "**How AlexNet Addressed LeNet-5's Limitations**\n",
    "\n",
    "AlexNet (by Krizhevsky et al., 2012) is a deeper, wider, and more scalable CNN that won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC 2012) by a huge margin.\n",
    "\n",
    "| LeNet Limitation                 | AlexNet's Solution                                                                                                 |\n",
    "| -------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Small input support**          | AlexNet processes **224Ã—224 RGB images**, suitable for real-world vision problems.                                 |\n",
    "| **Shallow depth**                | AlexNet has **8 layers (5 conv + 3 FC)**, allowing deeper and more abstract feature learning.                      |\n",
    "| **Tanh activation**              | Introduced **ReLU activation**, which accelerates convergence and mitigates vanishing gradients.                   |\n",
    "| **No GPU usage**                 | AlexNet was the **first major CNN trained on GPUs (2 Nvidia GTX 580s)** â€“ 10x faster training.                     |\n",
    "| **No dropout/regularization**    | Used **Dropout** in FC layers to prevent overfitting; also used data augmentation.                                 |\n",
    "| **Limited filters and channels** | AlexNet used **more filters (96 in first conv layer)** and **more feature maps**, allowing richer representations. |\n",
    "| **No normalization**             | Introduced **Local Response Normalization (LRN)** (though now outdated), to enhance generalization.                |\n",
    "\n",
    "\n",
    "**Visual Comparison (Simplified)**\n",
    "\n",
    "| Feature        | LeNet-5              | AlexNet                          |\n",
    "| -------------- | -------------------- | -------------------------------- |\n",
    "| Input          | 32Ã—32Ã—1              | 224Ã—224Ã—3                        |\n",
    "| Depth          | \\~7 layers           | 8 layers                         |\n",
    "| Activation     | Tanh                 | ReLU                             |\n",
    "| Regularization | None                 | Dropout                          |\n",
    "| GPU support    | No                   | Yes (2 GPUs)                     |\n",
    "| Dataset        | MNIST                | ImageNet                         |\n",
    "| Use Case       | Digit classification | Large-scale image classification |\n",
    "\n",
    "\n",
    "**Impact of AlexNet**\n",
    "\n",
    "    AlexNet:\n",
    "\n",
    "Revived interest in deep learning for computer vision.\n",
    "\n",
    "Showed CNNs could scale to large datasets with the right hardware (GPUs).\n",
    "\n",
    "Inspired deeper networks like VGG, GoogLeNet, and ResNet.\n",
    "\n",
    "Set the foundation for modern AI applications in vision tasks (autonomous vehicles, surveillance, AR, etc.)\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "While LeNet-5 was pioneering, it was limited to small, simple tasks. AlexNet overcame these limitations with a deeper design, modern training techniques, and hardware acceleration, marking the beginning of the deep learning revolution in computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255f65",
   "metadata": {},
   "source": [
    "4.  Explain the architecture of AlexNet and its contributions to the advancement of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d200631",
   "metadata": {},
   "source": [
    "**AlexNet: Architecture and Its Contributions to Deep Learning**\n",
    "\n",
    "**Overview of AlexNet**\n",
    "\n",
    "AlexNet is a deep convolutional neural network introduced by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton in 2012. It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 by a huge margin (top-5 error: 15.3% vs. 26.2%), marking a turning point in the field of deep learning and computer vision.\n",
    "\n",
    "**AlexNet Architecture**\n",
    "\n",
    "AlexNet processes RGB images of size 224Ã—224Ã—3 and consists of 8 layers:\n",
    "\n",
    "5 convolutional layers\n",
    "\n",
    "3 fully connected layers\n",
    "\n",
    "**Layer-by-Layer Breakdown**\n",
    "\n",
    "| Layer            | Type            | Details                                   | Output Size             |\n",
    "| ---------------- | --------------- | ----------------------------------------- | ----------------------- |\n",
    "| **Input**        | â€”               | 224Ã—224Ã—3 RGB image                       | 224Ã—224Ã—3               |\n",
    "| **Conv1**        | Convolution     | 96 filters of size 11Ã—11, stride 4 + ReLU | 55Ã—55Ã—96                |\n",
    "| **MaxPool1**     | Pooling         | 3Ã—3, stride 2                             | 27Ã—27Ã—96                |\n",
    "| **Conv2**        | Convolution     | 256 filters of size 5Ã—5 + ReLU            | 27Ã—27Ã—256               |\n",
    "| **MaxPool2**     | Pooling         | 3Ã—3, stride 2                             | 13Ã—13Ã—256               |\n",
    "| **Conv3**        | Convolution     | 384 filters of size 3Ã—3 + ReLU            | 13Ã—13Ã—384               |\n",
    "| **Conv4**        | Convolution     | 384 filters of size 3Ã—3 + ReLU            | 13Ã—13Ã—384               |\n",
    "| **Conv5**        | Convolution     | 256 filters of size 3Ã—3 + ReLU            | 13Ã—13Ã—256               |\n",
    "| **MaxPool3**     | Pooling         | 3Ã—3, stride 2                             | 6Ã—6Ã—256                 |\n",
    "| **FC6**          | Fully Connected | 4096 neurons + ReLU + Dropout             | 4096                    |\n",
    "| **FC7**          | Fully Connected | 4096 neurons + ReLU + Dropout             | 4096                    |\n",
    "| **FC8 (Output)** | Fully Connected | 1000 neurons + Softmax                    | 1000 classes (ImageNet) |\n",
    "\n",
    "\n",
    "**Key Features and Innovations in AlexNet**\n",
    "\n",
    "| Feature                                   | Description                                                                                          |\n",
    "| ----------------------------------------- | ---------------------------------------------------------------------------------------------------- |\n",
    "|  **ReLU Activation**                    | First large-scale use of **ReLU** instead of tanh/sigmoid â†’ much faster convergence.                 |\n",
    "|  **GPU Utilization**                    | Trained using **2 GPUs** (split layers), drastically improving training speed.                       |\n",
    "|  **Data Augmentation**                  | Applied transformations (cropping, flipping, color jitter) to **increase data diversity**.           |\n",
    "|  **Dropout Regularization**              | Used **dropout** in fully connected layers to prevent **overfitting**.                               |\n",
    "|  **Local Response Normalization (LRN)** | Introduced to mimic lateral inhibition in biological neurons (though no longer used in modern CNNs). |\n",
    "|  **Overlapping Max Pooling**            | Helps preserve more spatial information compared to non-overlapping pooling.                         |\n",
    "\n",
    "\n",
    "**Contributions to Deep Learning Advancement**\n",
    "\n",
    "1. Revived Convolutional Neural Networks\n",
    "\n",
    "CNNs were largely abandoned in the early 2000s.\n",
    "\n",
    "AlexNet revived deep learning, proving it could outperform traditional computer vision methods by a wide margin.\n",
    "\n",
    "2. Popularized GPU Training\n",
    "\n",
    "Showed that deep networks are practical if trained on GPUs.\n",
    "\n",
    "Inspired widespread GPU adoption for ML/DL research and industry.\n",
    "\n",
    "3. Template for Modern CNNs\n",
    "\n",
    "Inspired architectures like VGG, GoogLeNet, ResNet.\n",
    "\n",
    "Introduced core components (ReLU, Dropout, deep stack of layers) now standard in deep learning.\n",
    "\n",
    "4. Enabled Breakthroughs in Image Classification\n",
    "\n",
    "Achieved record-breaking performance on ImageNet (1.2 million images, 1000 classes).\n",
    "\n",
    "Demonstrated deep learning could scale to complex, real-world problems.\n",
    "\n",
    "**Visual Summary of AlexNet Architecture**\n",
    "\n",
    "\n",
    "Input (224x224x3)\n",
    "\n",
    "   â†“\n",
    "\n",
    "Conv1 (11x11, 96 filters, stride 4) + ReLU\n",
    "\n",
    "   â†“\n",
    "\n",
    "MaxPool (3x3, stride 2)\n",
    "\n",
    "   â†“\n",
    "\n",
    "Conv2 (5x5, 256 filters) + ReLU\n",
    "\n",
    "   â†“\n",
    "\n",
    "MaxPool (3x3)\n",
    "\n",
    "   â†“\n",
    "\n",
    "Conv3 (3x3, 384) â†’ Conv4 (3x3, 384) â†’ Conv5 (3x3, 256)\n",
    "\n",
    "   â†“\n",
    "\n",
    "MaxPool\n",
    "\n",
    "   â†“\n",
    "\n",
    "FC6 (4096) â†’ Dropout\n",
    "\n",
    "   â†“\n",
    "\n",
    "FC7 (4096) â†’ Dropout\n",
    "\n",
    "   â†“\n",
    "\n",
    "FC8 (1000) + Softmax\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "AlexNet was a breakthrough architecture that pushed deep learning into the spotlight. It tackled the limitations of LeNet-5 with deeper networks, faster training (via GPUs), and modern regularization techniques. Its legacy continues through todayâ€™s deep networks used in vision, speech, and NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa5d1a",
   "metadata": {},
   "source": [
    "5. Compare and contrast the architectures of LeNet-5 and AlexNet. Discuss their similarities, differences, \n",
    "and respective contributions to the field of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bc697",
   "metadata": {},
   "source": [
    "**Comparison of LeNet-5 and AlexNet**\n",
    "\n",
    "Both LeNet-5 and AlexNet are landmark CNN architectures that laid the foundation for deep learning in computer vision â€” but they differ greatly in complexity, scalability, and impact.\n",
    "\n",
    "**1. Side-by-Side Architectural Comparison**\n",
    "\n",
    "| Feature                    | **LeNet-5** (1998)                    | **AlexNet** (2012)                    |\n",
    "| -------------------------- | ------------------------------------- | ------------------------------------- |\n",
    "| **Designed by**            | Yann LeCun et al.                     | Alex Krizhevsky et al.                |\n",
    "| **Task**                   | Handwritten digit recognition (MNIST) | Object classification (ImageNet)      |\n",
    "| **Input Size**             | 32Ã—32Ã—1 (grayscale)                   | 224Ã—224Ã—3 (RGB)                       |\n",
    "| **Total Layers**           | 7                                     | 8                                     |\n",
    "| **Convolutional Layers**   | 3                                     | 5                                     |\n",
    "| **Fully Connected Layers** | 2 + output                            | 3 (FC6, FC7, FC8)                     |\n",
    "| **Activation Function**    | Tanh / Sigmoid                        | ReLU                                  |\n",
    "| **Pooling Type**           | Average Pooling                       | Max Pooling                           |\n",
    "| **Dropout**                |  No                                  |  Yes (FC layers)                     |\n",
    "| **GPU Usage**              |  No                                  |  Yes (2 GPUs)                        |\n",
    "| **Normalization**          |  No                                  |  Local Response Normalization (LRN)  |\n",
    "| **Data Augmentation**      |  No                                  |  Yes (cropping, flipping)            |\n",
    "| **Parameter Scale**        | \\~60K                                 | \\~60 million                          |\n",
    "| **Dataset**                | MNIST (60K samples)                   | ImageNet (1.2M samples, 1000 classes) |\n",
    "\n",
    "\n",
    "**2. Similarities**\n",
    "\n",
    "| Aspect                       | Description                                                                               |\n",
    "| ---------------------------- | ----------------------------------------------------------------------------------------- |\n",
    "| **CNN Foundation**           | Both use **convolution â†’ activation â†’ pooling â†’ fully connected** structure.              |\n",
    "| **Layer Types**              | Employ **convolutional layers** to extract features and **FC layers** for classification. |\n",
    "| **End-to-End Training**      | Both learn **features and classification jointly**, replacing hand-engineered features.   |\n",
    "| **Inspired by Neuroscience** | Both draw inspiration from the visual cortex and **local receptive fields**.              |\n",
    "\n",
    "\n",
    "**3. Key Differences**\n",
    "\n",
    "| Category                     | LeNet-5                                           | AlexNet                                                 |\n",
    "| ---------------------------- | ------------------------------------------------- | ------------------------------------------------------- |\n",
    "| **Depth and Complexity**     | Shallow (7 layers), suited for simple digits      | Deep (8 layers), designed for complex real-world images |\n",
    "| **Scalability**              | Not scalable to high-res color images             | Scales well to large datasets like ImageNet             |\n",
    "| **Performance Optimization** | No GPU usage; slow training                       | GPU training (2 GPUs), faster convergence               |\n",
    "| **Regularization**           | No dropout, no augmentation                       | Dropout + data augmentation + LRN                       |\n",
    "| **Activation Function**      | Tanh/Sigmoid (slow learning, vanishing gradients) | ReLU (fast convergence, non-saturating)                 |\n",
    "\n",
    "\n",
    "**4. Contributions to Deep Learning**\n",
    "\n",
    "    LeNet-5 Contributions:\n",
    "\n",
    "First successful CNN used in practical applications (e.g., bank check digit recognition).\n",
    "\n",
    "Demonstrated automatic feature extraction via convolution.\n",
    "\n",
    "Pioneered concepts like weight sharing, local receptive fields, and pooling.\n",
    "\n",
    "    AlexNet Contributions:\n",
    "\n",
    "Revived deep learning by winning ImageNet 2012 with a huge margin.\n",
    "\n",
    "Demonstrated the power of deep networks + GPUs on large-scale data.\n",
    "\n",
    "Introduced techniques like ReLU, dropout, and data augmentation that became standard.\n",
    "\n",
    "Sparked the development of deeper architectures (e.g., VGG, ResNet, Inception).\n",
    "\n",
    "**Visual Analogy**\n",
    "\n",
    "| Model       | Analogy                                                                                        |\n",
    "| ----------- | ---------------------------------------------------------------------------------------------- |\n",
    "| **LeNet-5** | Like a basic calculator â€” great for specific, simple tasks (digits)                            |\n",
    "| **AlexNet** | Like a modern computer â€” powerful enough to handle complex, large-scale tasks (natural images) |\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "| Summary                                                                                                                                           |\n",
    "| ------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| ðŸ”¹ **LeNet-5** laid the **foundation** of CNNs in the 1990s, proving they could learn from images.                                                |\n",
    "| ðŸ”¹ **AlexNet** showed how to **scale up** CNNs and train deep models on large datasets using GPUs.                                                |\n",
    "| Together, they represent a **major leap in deep learning evolution**, with LeNet as the prototype and AlexNet as the breakthrough into modern AI. |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
