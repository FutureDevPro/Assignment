{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41786504",
   "metadata": {},
   "source": [
    "1. Define image segmentation and discuss its importance in computer vision applications. Provide \n",
    "examples of tasks where image segmentation is crucial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53105534",
   "metadata": {},
   "source": [
    "**1. Definition of Image Segmentation:**\n",
    "\n",
    "Image segmentation is a computer vision technique that involves partitioning an image into multiple segments (sets of pixels) to simplify its representation and make it more meaningful and easier to analyze. The goal is to assign a label to every pixel in an image such that pixels with the same label share certain visual characteristics.\n",
    "\n",
    "**2. Importance of Image Segmentation in Computer Vision:**\n",
    "\n",
    "Image segmentation plays a crucial role in enabling machines to understand the content of images at a pixel level. It goes beyond object detection or classification by providing precise boundaries and shapes of objects in a scene.\n",
    "\n",
    "    Key reasons why segmentation is important:\n",
    "\n",
    "    Precise Localization: \n",
    "    \n",
    "Identifies the exact shape and boundary of objects.\n",
    "\n",
    "    Scene Understanding: \n",
    "    \n",
    "Helps machines understand the context of different regions in an image.\n",
    "\n",
    "    Improved Object Detection: \n",
    "    \n",
    "Enhances accuracy for detecting multiple, overlapping, or small objects.\n",
    "\n",
    "    Data for Further Analysis: \n",
    "    \n",
    "Enables measurements, tracking, and classification based on regions.\n",
    "\n",
    "**3. Types of Image Segmentation:**\n",
    "\n",
    "    Semantic Segmentation: \n",
    "    \n",
    "Classifies each pixel into a category (e.g., all 'cars' are labeled the same).\n",
    "\n",
    "    Instance Segmentation: \n",
    "    \n",
    "Distinguishes individual objects within the same class (e.g., car 1 vs. car 2).\n",
    "\n",
    "    Panoptic Segmentation: \n",
    "    \n",
    "Combines both semantic and instance segmentation for complete scene labeling.\n",
    "\n",
    "**4. Examples of Image Segmentation Use Cases:**\n",
    "\n",
    "    Autonomous Vehicles:\n",
    "\n",
    "Segmenting roads, pedestrians, vehicles, traffic signs to make safe driving decisions.\n",
    "\n",
    "    Medical Imaging:\n",
    "\n",
    "Identifying tumors, organs, or anatomical structures in CT, MRI, or X-ray images.\n",
    "\n",
    "    Photo Editing & Background Removal:\n",
    "\n",
    "Separating foreground from background for object cutouts, blurring, or replacements.\n",
    "\n",
    "    Satellite Image Analysis:\n",
    "\n",
    "Land use classification, disaster assessment (flood, fire zones), and urban planning.\n",
    "\n",
    "    Industrial Inspection:\n",
    "\n",
    "Defect detection in manufacturing lines (e.g., cracks, missing parts on circuit boards).\n",
    "\n",
    "    Face Recognition & Augmented Reality (AR):\n",
    "\n",
    "Segmenting facial features or human body parts for filters, virtual try-ons, or pose estimation.\n",
    "\n",
    "**5. Summary:**\n",
    "\n",
    "Image segmentation is fundamental for tasks requiring detailed analysis of image content. By assigning class labels to each pixel, it empowers systems to interpret images at a granular level, crucial for applications ranging from self-driving cars to healthcare diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea753a52",
   "metadata": {},
   "source": [
    "2. Explain the difference between semantic segmentation and instance segmentation. Provide examples \n",
    "of each and discuss their applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6f9c2",
   "metadata": {},
   "source": [
    "**Difference Between Semantic Segmentation and Instance Segmentation**\n",
    "\n",
    "| **Aspect**             | **Semantic Segmentation**                                             | **Instance Segmentation**                                             |\n",
    "| ---------------------- | --------------------------------------------------------------------- | --------------------------------------------------------------------- |\n",
    "| **Definition**         | Assigns a class label to **each pixel** in the image                  | Assigns a class label and **a unique ID** to **each object instance** |\n",
    "| **Object Distinction** | Does **not** differentiate between separate objects of the same class | **Distinguishes** each object, even if they belong to the same class  |\n",
    "| **Output**             | One mask per class                                                    | One mask per **object instance**                                      |\n",
    "| **Complexity**         | Simpler                                                               | More complex (combines object detection + segmentation)               |\n",
    "\n",
    "\n",
    "**Semantic Segmentation – Example & Applications**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "    In an image of a street scene:\n",
    "\n",
    "All pixels belonging to cars are labeled as \"car\"\n",
    "\n",
    "All roads are labeled as \"road\"\n",
    "\n",
    "All trees are labeled as \"tree\"\n",
    "\n",
    "    Even if there are 5 cars, all are treated as one class – \"car\".\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "Autonomous vehicles: Understanding drivable areas (road, sidewalk, pedestrian zones)\n",
    "\n",
    "Medical imaging: Labeling organ or tissue regions (e.g., segmenting liver, lungs)\n",
    "\n",
    "Agriculture: Crop vs. soil vs. weeds segmentation\n",
    "\n",
    "Satellite imagery: Land cover classification (forest, water, urban)\n",
    "\n",
    "**Instance Segmentation – Example & Applications**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "    In the same street scene:\n",
    "\n",
    "Car 1 is assigned a unique mask and ID\n",
    "\n",
    "Car 2 is assigned a different mask and ID\n",
    "\n",
    "Each pedestrian is uniquely segmented\n",
    "\n",
    "    So if there are 5 cars, each one is individually segmented and tracked.\n",
    "\n",
    "**Applications:**\n",
    "\n",
    "Robotics & autonomous systems: Precise object tracking for obstacle avoidance\n",
    "\n",
    "Retail & logistics: Counting and tracking products or packages\n",
    "\n",
    "Healthcare: Identifying individual cells or lesions in biomedical images\n",
    "\n",
    "AR/VR: Accurate object manipulation in virtual environments\n",
    "\n",
    " **Summary:**\n",
    "\n",
    " |                   | **Semantic Segmentation**                | **Instance Segmentation**                      |\n",
    "| ----------------- | ---------------------------------------- | ---------------------------------------------- |\n",
    "| Goal              | Classify pixels into classes             | Classify and **separate each object instance** |\n",
    "| Multiple Objects  | All objects of the same class = one mask | Each object = unique mask                      |\n",
    "| Example           | “All cars” → same label                  | “Car 1”, “Car 2” → separate labels             |\n",
    "| Application Focus | Scene understanding                      | Object-level interaction and analysis          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ddea1",
   "metadata": {},
   "source": [
    "3. Discuss the challenges faced in image segmentation, such as occlusions, object variability, and \n",
    "boundary ambiguity. Propose potential solutions or techniques to address these challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173059b",
   "metadata": {},
   "source": [
    "**Challenges in Image Segmentation and Their Solutions**\n",
    "\n",
    "Image segmentation, especially in complex real-world settings, faces several challenges that affect accuracy and reliability. Below are the key challenges and their solutions:\n",
    "\n",
    "**1. Occlusion (Object Overlap)**\n",
    "\n",
    "    Problem:\n",
    "\n",
    "Objects may partially or fully block each other in the image (e.g., a person standing in front of a car), making it difficult to segment them accurately.\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Confused boundaries\n",
    "\n",
    "Merged objects\n",
    "\n",
    "Missed instances\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Instance segmentation models (e.g., Mask R-CNN) – distinguish overlapping objects\n",
    "\n",
    "Depth-aware segmentation – using 3D data (RGB-D or LiDAR) to understand object separation\n",
    "\n",
    "Attention mechanisms – focus on salient regions to distinguish foreground from background\n",
    "\n",
    "**2. Object Variability (Shape, Scale, Pose, Appearance)**\n",
    "\n",
    "    Problem:\n",
    "\n",
    "Objects of the same class can look very different in size, orientation, lighting, and shape (e.g., dogs of different breeds, cars in different poses).\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Inconsistent classification\n",
    "\n",
    "Poor generalization\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Data augmentation – rotations, scaling, flipping, color jittering\n",
    "\n",
    "Multi-scale feature extraction – architectures like FPN (Feature Pyramid Network)\n",
    "\n",
    "Deep learning with CNNs and Transformers – learn invariant features across samples\n",
    "\n",
    "Transfer learning – leverage pre-trained models on large datasets (e.g., COCO, ImageNet)\n",
    "\n",
    "**3. Boundary Ambiguity**\n",
    "\n",
    "    Problem:\n",
    "\n",
    "Object boundaries may be blurred, faded, or very close to the background color (e.g., white cat on a snowy background).\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Imprecise segmentation masks\n",
    "\n",
    "Leaky or broken contours\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Edge-aware loss functions – e.g., boundary loss, dice loss\n",
    "\n",
    "Refinement networks – U-Net with skip connections, DeepLabv3+ with atrous convolutions\n",
    "\n",
    "Conditional Random Fields (CRFs) – post-processing to sharpen edges\n",
    "\n",
    "High-resolution input – preserves fine-grained details\n",
    "\n",
    "**4. Class Imbalance**\n",
    "\n",
    "    Problem:\n",
    "\n",
    "Some classes may occupy very few pixels compared to others (e.g., tiny objects vs. large background), leading to biased training.\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Model ignores small or rare classes\n",
    "\n",
    "Solutions:\n",
    "\n",
    "Weighted loss functions – e.g., focal loss, weighted cross-entropy\n",
    "\n",
    "Patch-based training – focus on regions of interest\n",
    "\n",
    "Oversampling/undersampling – balance dataset distribution\n",
    "\n",
    "**5. Real-Time Processing Constraints**\n",
    "\n",
    "    Problem:    \n",
    "\n",
    "Many applications (e.g., self-driving cars, medical scans) require fast, accurate segmentation.\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Trade-off between speed and accuracy\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Lightweight models – like DeepLabV3+ MobileNet, Fast-SCNN\n",
    "\n",
    "Model pruning and quantization – reduce model size and inference time\n",
    "\n",
    "Edge computing or GPU acceleration – run models efficiently on devices\n",
    "\n",
    "**6. Domain Shift / Dataset Bias**\n",
    "\n",
    "    Problem:   \n",
    "\n",
    "Models trained on one dataset (e.g., daytime street scenes) may perform poorly on different domains (e.g., nighttime or rainy scenes).\n",
    "\n",
    "    Impact:\n",
    "\n",
    "Poor generalization to unseen environments\n",
    "\n",
    "    Solutions:\n",
    "\n",
    "Domain adaptation – fine-tune on target domain\n",
    "\n",
    "Unsupervised/Semi-supervised learning – use unlabeled data from the new domain\n",
    "\n",
    "Synthetic data generation – augment training with realistic variations (GANs or simulations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145aca4",
   "metadata": {},
   "source": [
    "**Summary Table**\n",
    "\n",
    "| **Challenge**         | **Impact**                   | **Solution**                            |\n",
    "| --------------------- | ---------------------------- | --------------------------------------- |\n",
    "| Occlusion             | Merged or missed objects     | Mask R-CNN, depth maps, attention       |\n",
    "| Object variability    | Poor generalization          | Data augmentation, multi-scale learning |\n",
    "| Boundary ambiguity    | Inaccurate edges             | Edge-aware loss, CRFs, high-res input   |\n",
    "| Class imbalance       | Bias toward dominant classes | Weighted loss, patch training           |\n",
    "| Real-time constraints | Slow inference               | Lightweight models, pruning             |\n",
    "| Domain shift          | Drop in accuracy on new data | Domain adaptation, synthetic data       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632c76c5",
   "metadata": {},
   "source": [
    "4. Explain the working principles of popular image segmentation algorithms such as U-Net and Mask R\n",
    "CNN. Compare their architectures, strengths, and weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e621d",
   "metadata": {},
   "source": [
    "**Image Segmentation Algorithms: U-Net vs. Mask R-CNN**\n",
    "\n",
    "U-Net and Mask R-CNN are two widely used deep learning architectures for image segmentation, each designed for different types of tasks. Let's understand their working principles, architecture comparison, strengths, and weaknesses.\n",
    "\n",
    "**U-Net**\n",
    "\n",
    "Type: Semantic Segmentation\n",
    "\n",
    "Goal: Classify each pixel into a class (but not separate object instances)\n",
    "\n",
    "**Working Principle:**\n",
    "\n",
    "    U-Net uses a symmetric encoder–decoder architecture:\n",
    "\n",
    "1. Encoder (Contracting Path):\n",
    "\n",
    "Downsamples the image using convolutional + pooling layers.\n",
    "\n",
    "Captures context and features at multiple levels.\n",
    "\n",
    "2. Decoder (Expanding Path):\n",
    "\n",
    "Upsamples using transposed convolutions (deconvolution).\n",
    "\n",
    "Reconstructs the image segmentation mask.\n",
    "\n",
    "3. Skip Connections:\n",
    "\n",
    "Directly connect layers from encoder to decoder.\n",
    "\n",
    "Help recover spatial information lost during downsampling.\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    "\n",
    "Input Image → [Conv → Pool] x N → Bottleneck → [Upsample → Conv] x N → Output Mask\n",
    "\n",
    "        |_____________________________________|\n",
    "                    (Skip Connections)\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "Works well with small datasets (originally for medical imaging).\n",
    "\n",
    "Precise pixel-level segmentation.\n",
    "\n",
    "Simple and fast to train.\n",
    "\n",
    "Effective for semantic segmentation tasks.\n",
    "\n",
    "**Weaknesses:**\n",
    "\n",
    "Cannot differentiate instances of the same object class (e.g., 2 dogs = 1 mask).\n",
    "\n",
    "Performance drops on complex real-world scenes with object overlap.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Mask R-CNN**\n",
    "\n",
    "Type: Instance Segmentation\n",
    "\n",
    "Goal: Detect objects and generate a binary mask for each instance\n",
    "\n",
    "**Working Principle:**\n",
    "\n",
    "Mask R-CNN is an extension of Faster R-CNN (object detection model):\n",
    "\n",
    "1. Backbone (Feature Extractor):\n",
    "\n",
    "Typically uses ResNet + Feature Pyramid Network (FPN).\n",
    "\n",
    "Extracts image features at multiple scales.\n",
    "\n",
    "2. Region Proposal Network (RPN):\n",
    "\n",
    "Proposes regions (bounding boxes) likely to contain objects.\n",
    "\n",
    "3. RoI Align:\n",
    "\n",
    "Aligns proposed regions with the feature maps without spatial distortion.\n",
    "\n",
    "4. Heads for Output:\n",
    "\n",
    "Classification Head: Predicts class label.\n",
    "\n",
    "Bounding Box Head: Refines box coordinates.\n",
    "\n",
    "Mask Head: Outputs a segmentation mask per instance (a small CNN branch).\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    "Image → CNN Backbone → RPN → RoI Align\n",
    "         → [Box Head, Class Head, Mask Head] → Output: Boxes + Labels + Masks\n",
    "\n",
    "**Strengths:**\n",
    "\n",
    "Performs detection + segmentation in a unified framework.\n",
    "\n",
    "Handles multiple object instances (instance segmentation).\n",
    "\n",
    "Works well on real-world scenes (e.g., COCO dataset).\n",
    "\n",
    "**Weaknesses:**\n",
    "\n",
    "Slower than U-Net due to its two-stage pipeline.\n",
    "\n",
    "More complex to train and tune.\n",
    "\n",
    "Requires large datasets and high computational power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775cdd4e",
   "metadata": {},
   "source": [
    "**Comparison Table**\n",
    "\n",
    "\n",
    "| **Aspect**                     | **U-Net**                         | **Mask R-CNN**                           |\n",
    "| ------------------------------ | --------------------------------- | ---------------------------------------- |\n",
    "| **Segmentation Type**          | Semantic Segmentation             | Instance Segmentation                    |\n",
    "| **Architecture**               | Encoder–Decoder with Skip Paths   | Object Detector + Segmentation Mask Head |\n",
    "| **Handles Multiple Instances** |  No                              |  Yes                                    |\n",
    "| **Speed**                      |  Fast                            |  Slower                                 |\n",
    "| **Complexity**                 | Low                               | High                                     |\n",
    "| **Use Case**                   | Medical imaging, satellite images | Object detection with masks (e.g., COCO) |\n",
    "| **Output**                     | One mask per class                | One mask per instance                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4eb9c9",
   "metadata": {},
   "source": [
    "**When to Use Which?**\n",
    "\n",
    "    Use U-Net when:\n",
    "\n",
    "- You need pixel-level accuracy for each class\n",
    "\n",
    "- Instances don't need to be separated\n",
    "\n",
    "- You're working with small or limited datasets\n",
    "\n",
    "- Tasks like tumor segmentation, organ detection\n",
    "\n",
    "        Use Mask R-CNN when:   \n",
    "\n",
    "- You need to detect and segment each object\n",
    "\n",
    "- Instances of the same class need to be separated\n",
    "\n",
    "- You're working with general object detection\n",
    "\n",
    "- Applications like COCO, real-world scene parsing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f393c8",
   "metadata": {},
   "source": [
    "5. Evaluate the performance of image segmentation algorithms on standard benchmark datasets such \n",
    "as Pascal VOC and COCO. Compare and analyze the results of different algorithms in terms of \n",
    "accuracy, speed, and memory efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b014168",
   "metadata": {},
   "source": [
    "**Evaluation of Image Segmentation Algorithms on Standard Benchmarks (Pascal VOC & COCO)**\n",
    "\n",
    "Popular image segmentation models like U-Net, DeepLabv3+, Mask R-CNN, HRNet, and YOLO-based segmenters have been rigorously tested on standard datasets such as Pascal VOC and COCO. These benchmarks help in comparing algorithms based on accuracy, speed, and memory efficiency.\n",
    "\n",
    "**Benchmark Datasets Overview**\n",
    "\n",
    "**Pascal VOC (Visual Object Classes)**\n",
    "\n",
    "Tasks: Semantic segmentation\n",
    "\n",
    "Classes: 20 object classes + background\n",
    "\n",
    "Evaluation Metric: mIoU (Mean Intersection over Union)\n",
    "\n",
    "**COCO (Common Objects in Context)**\n",
    "\n",
    "Tasks: Instance segmentation, object detection, keypoint detection\n",
    "\n",
    "Classes: 80 object categories\n",
    "\n",
    "Evaluation Metric: AP (Average Precision) @ different IoU thresholds (e.g., AP@[0.5:0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef95031",
   "metadata": {},
   "source": [
    "| **Model**      | **Type**                        | **Pascal VOC (mIoU%)** | **COCO (Mask AP%)** | **Speed (FPS)**       | **Memory Efficiency** | **Notes**                              |\n",
    "| -------------- | ------------------------------- | ---------------------- | ------------------- | --------------------- | --------------------- | -------------------------------------- |\n",
    "| **U-Net**      | Semantic Segmentation           | \\~76%                  | N/A                 |  Fast (15–30)        |  Lightweight         | Great for medical & small datasets     |\n",
    "| **DeepLabv3+** | Semantic Segmentation           | \\~85%                  | \\~42%               |  Moderate (5–15)    |  Heavy              | High accuracy with Atrous convolutions |\n",
    "| **Mask R-CNN** | Instance Segmentation           | N/A                    | \\~38%               |  Slow (2–5)          |  High memory usage   | Accurate but slow                      |\n",
    "| **YOLOv8-Seg** | Real-time Instance Segmentation | \\~72–75%               | \\~35–37%            |  Very Fast (30–60+) |  Efficient           | Speed + deployment ready               |\n",
    "| **HRNet**      | Semantic Segmentation           | \\~84–86%               | \\~41%               |  Moderate (5–10)    |  Heavy              | Maintains high-resolution throughout   |\n",
    "| **PointRend**  | Instance Segmentation           | N/A                    | \\~40%               |  Slow (2–4)         |  Moderate/High       | Refines mask boundaries with detail    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91260e",
   "metadata": {},
   "source": [
    "**Accuracy Analysis**\n",
    "\n",
    "DeepLabv3+ and HRNet consistently achieve high mIoU on Pascal VOC, suitable for tasks needing precise semantic segmentation.\n",
    "\n",
    "Mask R-CNN is one of the best for instance segmentation, but newer approaches like PointRend or CondInst offer better mask quality at fine edges.\n",
    "\n",
    "YOLOv8-Seg is a newer real-time method that trades off a bit of accuracy for significantly better inference speed and efficiency, great for edge deployment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f2d3a",
   "metadata": {},
   "source": [
    "**Speed (Inference Time)**\n",
    "\n",
    "| Model      | Speed Target      | Notes                                      |\n",
    "| ---------- | ----------------- | ------------------------------------------ |\n",
    "| U-Net      | Fast              | Ideal for real-time medical imaging        |\n",
    "| DeepLabv3+ | Moderate          | Slower due to large backbone like Xception |\n",
    "| Mask R-CNN | Slow              | Two-stage process is compute-heavy         |\n",
    "| YOLOv8-Seg |  Real-time Ready | Up to 60+ FPS on GPU                       |\n",
    "| HRNet      | Moderate          | High accuracy, but speed trade-off         |\n",
    "| PointRend  | Slow              | Focuses on mask refinement, not speed      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68a168",
   "metadata": {},
   "source": [
    "**Memory Efficiency**\n",
    "\n",
    "U-Net and YOLOv8-Seg are lightweight, suitable for embedded systems or edge devices.\n",
    "\n",
    "DeepLabv3+, HRNet, and Mask R-CNN require more memory and are GPU-dependent.\n",
    "\n",
    "Mask R-CNN with large backbones (e.g., ResNet-101, ResNeXt) needs 8–16GB GPU for batch inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220c14f",
   "metadata": {},
   "source": [
    "**Summary Table**\n",
    "\n",
    "| **Algorithm** | **Pascal VOC** | **COCO** | **Best For**                               | **Weakness**                    |\n",
    "| ------------- | -------------- | -------- | ------------------------------------------ | ------------------------------- |\n",
    "| U-Net         |  High (76%)   |  N/A    | Biomedical, small-scale tasks              | Can't separate instances        |\n",
    "| DeepLabv3+    |  Best (\\~85%) |  Good   | High-accuracy semantic segmentation        | Slow, memory-heavy              |\n",
    "| Mask R-CNN    |  N/A          |  Good   | Instance segmentation                      | Slow, large model size          |\n",
    "| YOLOv8-Seg    |  Moderate    |  Good   | Real-time instance segmentation, mobile AI | Slightly lower mask accuracy    |\n",
    "| HRNet         |  Very High    |  Good   | High-res segmentation, human parsing       | Memory and speed limitations    |\n",
    "| PointRend     |  N/A          |  Better | High-quality edge masks                    | Slower than standard Mask R-CNN |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
